{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPl4oQMsrWk7mfDWYbFfOOe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hivani/-Question-Answering-system-using-an-LLM-/blob/main/steps_AI_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Advanced Chunking of Data***"
      ],
      "metadata": {
        "id": "C1uydgNft46m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpRth-COBF5E",
        "outputId": "ba85891e-4886-4586-b37b-81fff2096ddb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.41.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.23.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.5.82)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Load JSON Data\n",
        "with open('/content/scraped_data.json') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Initialize the Sentence Transformer model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Function to chunk data based on semantic similarity\n",
        "def chunk_data(doc):\n",
        "    sentences = doc.split('. ')\n",
        "    embeddings = model.encode(sentences)\n",
        "    clusters = util.community_detection(embeddings, min_community_size=2)\n",
        "    chunks = [' '.join([sentences[idx] for idx in cluster]) for cluster in clusters]\n",
        "    return chunks\n",
        "\n",
        "# Chunk all documents\n",
        "all_chunks = []\n",
        "for entry in data:\n",
        "    chunks = chunk_data(entry['content'])\n",
        "    for chunk in chunks:\n",
        "        all_chunks.append({\n",
        "            'text': chunk,\n",
        "            'meta': {'web_link': entry.get('web_link', 'N/A')}\n",
        "        })\n",
        "\n",
        "print(f\"Total chunks created: {len(all_chunks)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "188sDufFkTvc",
        "outputId": "0b10fcf0-fe68-4ce6-fedb-1bf94d7b7067"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total chunks created: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def parse_html_content(html_content):\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "    output = \"\"\n",
        "    for dt, dd in zip(soup.find_all('dt'), soup.find_all('dd')):\n",
        "        title = dt.text.strip()\n",
        "        description = dd.p.text.strip()\n",
        "        output += f\"{title}: {description}\\n\\n\"\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "oPVgxyiceNlK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Convert Data to Embedding Vectors***"
      ],
      "metadata": {
        "id": "pgK8K2eTuOB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert text chunks to embedding vectors\n",
        "chunk_texts = [chunk['text'] for chunk in all_chunks]\n",
        "chunk_embeddings = model.encode(chunk_texts)\n"
      ],
      "metadata": {
        "id": "_OR3m_Afknld"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install grpcio==1.63.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkhUlTsJnirG",
        "outputId": "f6033635-c79c-45e8-e434-d513a1df8f38"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: grpcio==1.63.0 in /usr/local/lib/python3.10/dist-packages (1.63.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TfcscY5pPgQ",
        "outputId": "c58773b5-05b2-48b5-eb7d-b3c31f158814"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.8.0.post1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Create Vector Database **"
      ],
      "metadata": {
        "id": "5Wg2x4mKuTZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# Convert the embeddings to float32\n",
        "chunk_embeddings = np.array(chunk_embeddings).astype('float32')\n",
        "\n",
        "# Create a FAISS index\n",
        "dimension = chunk_embeddings.shape[1]\n",
        "index = faiss.IndexHNSWFlat(dimension, 32)  # HNSW index with 32 neighbors\n",
        "index.hnsw.efConstruction = 200\n",
        "\n",
        "# Add embeddings to the index\n",
        "index.add(chunk_embeddings)\n",
        "\n",
        "# Store metadata (in-memory for simplicity, you may use a database or file)\n",
        "metadata = [{'web_link': chunk['meta']['web_link']} for chunk in all_chunks]\n"
      ],
      "metadata": {
        "id": "IzCuU6cakxZh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ** Retrieval and Re-ranking**"
      ],
      "metadata": {
        "id": "2unQ39YKubdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Use a simple query expansion technique (e.g., synonyms)\n",
        "def expand_query(query):\n",
        "    synonyms = [\"synonym1\", \"synonym2\"]  # Example synonyms\n",
        "    expanded_query = f\"{query} {' '.join(synonyms)}\"\n",
        "    return expanded_query\n",
        "\n",
        "# Expand the query\n",
        "query = \"example query\"\n",
        "expanded_query = expand_query(query)\n"
      ],
      "metadata": {
        "id": "6YewzHKbr7sM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hybrid Retrieval Methods**"
      ],
      "metadata": {
        "id": "Mbk2xNHTug6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Encode the query\n",
        "query_embedding = model.encode([expanded_query]).astype('float32')\n",
        "\n",
        "# Search the index\n",
        "k = 10  # Number of nearest neighbors\n",
        "distances, indices = index.search(query_embedding, k)\n",
        "\n",
        "# Extract results\n",
        "retrieved_chunks = [chunk_texts[i] for i in indices[0]]\n",
        "retrieved_metadata = [metadata[i] for i in indices[0]]\n",
        "\n",
        "print(f\"Retrieved Chunks: {retrieved_chunks}\")\n",
        "print(f\"Retrieved Metadata: {retrieved_metadata}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rlhe67Dr87i",
        "outputId": "8752fc2e-2f77-43f6-9b1e-9af4cdadac97"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved Chunks: ['This guide summarizes the ways that applications can be fine-tuned to gain additional speedups by leveraging Hopper GPU Architectureâ\\x80\\x99s features.</p>\\r\\n</dd>\\r\\n<dt><a class=\"reference internal\" href=\"ada-tuning-guide/index.html\"><span class=\"doc\">Ada Tuning Guide</span></a></dt><dd><p>The NVIDIAÂ® Ada GPU architecture is NVIDIAâ\\x80\\x99s latest architecture for CUDAÂ® compute applications This guide summarizes the ways that applications can be fine-tuned to gain additional speedups by leveraging NVIDIA Ampere GPU Architectureâ\\x80\\x99s features.</p>\\r\\n</dd>\\r\\n<dt><a class=\"reference internal\" href=\"hopper-tuning-guide/index.html\"><span class=\"doc\">Hopper Tuning Guide</span></a></dt><dd><p>Hopper GPU Architecture is NVIDIAâ\\x80\\x99s 9th-generation architecture for CUDA compute applications This guide summarizes the ways that applications can be fine-tuned to gain additional speedups by leveraging Turing architectural features.</p>\\r\\n</dd>\\r\\n<dt><a class=\"reference internal\" href=\"ampere-tuning-guide/index.html\"><span class=\"doc\">NVIDIA Ampere GPU Architecture Tuning Guide</span></a></dt><dd><p>NVIDIA Ampere GPU Architecture is NVIDIAâ\\x80\\x99s 8th-generation architecture for CUDA compute applications This guide summarizes the ways that applications can be fine-tuned to gain additional speedups by leveraging Maxwell architectural features.</p>\\r\\n</dd>\\r\\n<dt><a class=\"reference internal\" href=\"pascal-tuning-guide/index.html\"><span class=\"doc\">Pascal Tuning Guide</span></a></dt><dd><p>Pascal is NVIDIAâ\\x80\\x99s 5th-generation architecture for CUDA compute applications This guide summarizes the ways that applications can be fine-tuned to gain additional speedups by leveraging Pascal architectural features.</p>\\r\\n</dd>\\r\\n<dt><a class=\"reference internal\" href=\"volta-tuning-guide/index.html\"><span class=\"doc\">Volta Tuning Guide</span></a></dt><dd><p>Volta is NVIDIAâ\\x80\\x99s 6th-generation architecture for CUDA compute applications This guide summarizes the ways that applications can be fine-tuned to gain additional speedups by leveraging Volta architectural features.</p>\\r\\n</dd>\\r\\n<dt><a class=\"reference internal\" href=\"turing-tuning-guide/index.html\"><span class=\"doc\">Turing Tuning Guide</span></a></dt><dd><p>Turing is NVIDIAâ\\x80\\x99s 7th-generation architecture for CUDA compute applications Applications that follow the best practices for the NVIDIA Volta architecture should typically see speedups on the Hopper GPU Architecture without any code changes This guide summarizes the ways that an application can be fine-tuned to gain additional speedups by leveraging the NVIDIA Ada GPU architectureâ\\x80\\x99s features.</p>\\r\\n</dd>\\r\\n<dt><a class=\"reference internal\" href=\"parallel-thread-execution/index.html\"><span class=\"doc\">PTX ISA</span></a></dt><dd><p>This guide provides detailed instructions on the use of PTX, a low-level parallel thread execution virtual machine and instruction set architecture (ISA)', 'This document provides guidance to ensure that your software applications are compatible with NVIDIA Ampere GPU architecture.</p>\\r\\n</dd>\\r\\n<dt><a class=\"reference internal\" href=\"hopper-compatibility-guide/index.html\"><span class=\"doc\">Hopper Compatibility Guide</span></a></dt><dd><p>This application note is intended to help developers ensure that their NVIDIA CUDA applications will run properly on the Hopper GPUs This document provides guidance to ensure that your software applications are compatible with Hopper architecture.</p>\\r\\n</dd>\\r\\n<dt><a class=\"reference internal\" href=\"ada-compatibility-guide/index.html\"><span class=\"doc\">Ada Compatibility Guide</span></a></dt><dd><p>This application note is intended to help developers ensure that their NVIDIA CUDA applications will run properly on the Ada GPUs', 'This document provides guidance to ensure that your software applications are compatible with Volta.</p>\\r\\n</dd>\\r\\n<dt><a class=\"reference internal\" href=\"turing-compatibility-guide/index.html\"><span class=\"doc\">Turing Compatibility Guide</span></a></dt><dd><p>This application note is intended to help developers ensure that their NVIDIA CUDA applications will run properly on GPUs based on the NVIDIA Turing Architecture This document provides guidance to ensure that your software applications are compatible with Turing.</p>\\r\\n</dd>\\r\\n<dt><a class=\"reference internal\" href=\"ampere-compatibility-guide/index.html\"><span class=\"doc\">NVIDIA Ampere GPU Architecture Compatibility Guide</span></a></dt><dd><p>This application note is intended to help developers ensure that their NVIDIA CUDA applications will run properly on GPUs based on the NVIDIA Ampere GPU Architecture', 'This document provides guidance to ensure that your software applications are compatible with Maxwell.</p>\\r\\n</dd>\\r\\n<dt><a class=\"reference internal\" href=\"pascal-compatibility-guide/index.html\"><span class=\"doc\">Pascal Compatibility Guide</span></a></dt><dd><p>This application note is intended to help developers ensure that their NVIDIA CUDA applications will run properly on GPUs based on the NVIDIA Pascal Architecture This document provides guidance to ensure that your software applications are compatible with Pascal.</p>\\r\\n</dd>\\r\\n<dt><a class=\"reference internal\" href=\"volta-compatibility-guide/index.html\"><span class=\"doc\">Volta Compatibility Guide</span></a></dt><dd><p>This application note is intended to help developers ensure that their NVIDIA CUDA applications will run properly on GPUs based on the NVIDIA Volta Architecture This document provides guidance to ensure that your software applications are compatible with Ada architecture.</p>\\r\\n</dd>\\r\\n<dt><a class=\"reference internal\" href=\"maxwell-tuning-guide/index.html\"><span class=\"doc\">Maxwell Tuning Guide</span></a></dt><dd><p>Maxwell is NVIDIAâ\\x80\\x99s 4th-generation architecture for CUDA compute applications The intent is to provide guidelines for obtaining the best performance from NVIDIA GPUs using the CUDA Toolkit.</p>\\r\\n</dd>\\r\\n<dt><a class=\"reference internal\" href=\"maxwell-compatibility-guide/index.html\"><span class=\"doc\">Maxwell Compatibility Guide</span></a></dt><dd><p>This application note is intended to help developers ensure that their NVIDIA CUDA applications will run properly on GPUs based on the NVIDIA Maxwell Architecture', 'Applications that follow the best practices for the Pascal architecture should typically see speedups on the Volta architecture without any code changes Applications that follow the best practices for the NVIDIA Volta architecture should typically see speedups on the NVIDIA Ampere GPU Architecture without any code changes Applications that follow the best practices for the Maxwell architecture should typically see speedups on the Pascal architecture without any code changes Applications that follow the best practices for the Pascal architecture should typically see speedups on the Turing architecture without any code changes', 'This document provides guidance to ensure that your software applications are compatible with NVIDIA Ampere GPU architecture.</p>\\r\\n</dd>\\r\\n<dt><a class=\"reference internal\" href=\"hopper-compatibility-guide/index.html\"><span class=\"doc\">Hopper Compatibility Guide</span></a></dt><dd><p>This application note is intended to help developers ensure that their NVIDIA CUDA applications will run properly on the Hopper GPUs This document provides guidance to ensure that your software applications are compatible with Hopper architecture.</p>\\r\\n</dd>\\r\\n<dt><a class=\"reference internal\" href=\"ada-compatibility-guide/index.html\"><span class=\"doc\">Ada Compatibility Guide</span></a></dt><dd><p>This application note is intended to help developers ensure that their NVIDIA CUDA applications will run properly on the Ada GPUs', 'This document provides guidance to ensure that your software applications are compatible with NVIDIA Ampere GPU architecture.</p>\\r\\n</dd>\\r\\n<dt><a class=\"reference internal\" href=\"hopper-compatibility-guide/index.html\"><span class=\"doc\">Hopper Compatibility Guide</span></a></dt><dd><p>This application note is intended to help developers ensure that their NVIDIA CUDA applications will run properly on the Hopper GPUs This document provides guidance to ensure that your software applications are compatible with Hopper architecture.</p>\\r\\n</dd>\\r\\n<dt><a class=\"reference internal\" href=\"ada-compatibility-guide/index.html\"><span class=\"doc\">Ada Compatibility Guide</span></a></dt><dd><p>This application note is intended to help developers ensure that their NVIDIA CUDA applications will run properly on the Ada GPUs', 'This document provides guidance to ensure that your software applications are compatible with NVIDIA Ampere GPU architecture.</p>\\r\\n</dd>\\r\\n<dt><a class=\"reference internal\" href=\"hopper-compatibility-guide/index.html\"><span class=\"doc\">Hopper Compatibility Guide</span></a></dt><dd><p>This application note is intended to help developers ensure that their NVIDIA CUDA applications will run properly on the Hopper GPUs This document provides guidance to ensure that your software applications are compatible with Hopper architecture.</p>\\r\\n</dd>\\r\\n<dt><a class=\"reference internal\" href=\"ada-compatibility-guide/index.html\"><span class=\"doc\">Ada Compatibility Guide</span></a></dt><dd><p>This application note is intended to help developers ensure that their NVIDIA CUDA applications will run properly on the Ada GPUs', 'This document provides guidance to ensure that your software applications are compatible with NVIDIA Ampere GPU architecture.</p>\\r\\n</dd>\\r\\n<dt><a class=\"reference internal\" href=\"hopper-compatibility-guide/index.html\"><span class=\"doc\">Hopper Compatibility Guide</span></a></dt><dd><p>This application note is intended to help developers ensure that their NVIDIA CUDA applications will run properly on the Hopper GPUs This document provides guidance to ensure that your software applications are compatible with Hopper architecture.</p>\\r\\n</dd>\\r\\n<dt><a class=\"reference internal\" href=\"ada-compatibility-guide/index.html\"><span class=\"doc\">Ada Compatibility Guide</span></a></dt><dd><p>This application note is intended to help developers ensure that their NVIDIA CUDA applications will run properly on the Ada GPUs', 'This document provides guidance to ensure that your software applications are compatible with NVIDIA Ampere GPU architecture.</p>\\r\\n</dd>\\r\\n<dt><a class=\"reference internal\" href=\"hopper-compatibility-guide/index.html\"><span class=\"doc\">Hopper Compatibility Guide</span></a></dt><dd><p>This application note is intended to help developers ensure that their NVIDIA CUDA applications will run properly on the Hopper GPUs This document provides guidance to ensure that your software applications are compatible with Hopper architecture.</p>\\r\\n</dd>\\r\\n<dt><a class=\"reference internal\" href=\"ada-compatibility-guide/index.html\"><span class=\"doc\">Ada Compatibility Guide</span></a></dt><dd><p>This application note is intended to help developers ensure that their NVIDIA CUDA applications will run properly on the Ada GPUs']\n",
            "Retrieved Metadata: [{'web_link': 'N/A'}, {'web_link': 'N/A'}, {'web_link': 'N/A'}, {'web_link': 'N/A'}, {'web_link': 'N/A'}, {'web_link': 'N/A'}, {'web_link': 'N/A'}, {'web_link': 'N/A'}, {'web_link': 'N/A'}, {'web_link': 'N/A'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-rank the retrieved results\n",
        "reranked_results = util.semantic_search(model.encode(query), model.encode(retrieved_chunks), top_k=10)\n",
        "\n",
        "# Flatten the re-ranked results\n",
        "reranked_chunks = [retrieved_chunks[idx['corpus_id']] for idx in reranked_results[0]]\n"
      ],
      "metadata": {
        "id": "WuzD-Pl4r_GM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Initialize QA pipeline\n",
        "qa_pipeline = pipeline('question-answering', model='deepset/roberta-base-squad2')\n"
      ],
      "metadata": {
        "id": "7i0lanazsCFr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the top re-ranked result for question answering\n",
        "context = reranked_chunks[0]\n",
        "answer = qa_pipeline({'question': query, 'context': context})\n",
        "\n",
        "print(f\"Answer: {answer['answer']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bX7_Vv-MsE72",
        "outputId": "2c7037da-f2c1-4abc-9c6d-e2c1b0486d16"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: NVIDIA Ampere GPU Architecture\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2hlKge0vcwU",
        "outputId": "69985dec-0c72-4ede-c1b7-5fdac337bdd0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.36.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.25.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.0.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: watchdog<5,>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.0.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.7.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.19.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install streamlit -q"
      ],
      "metadata": {
        "id": "FfB3R4SNDliN"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZMkh1IlD5eE",
        "outputId": "ae5360c9-6397-40c5-b8d7-5cdbc02b2cf7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.125.202.28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjO1NeZXELvB",
        "outputId": "8736b4ce-0bff-4e99-9007-cbea37ba7045"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.125.202.28:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.167s\n",
            "your url is: https://curly-foxes-smile.loca.lt\n",
            "2024-07-16 17:03:18.451091: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-16 17:03:18.451152: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-16 17:03:18.452654: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-16 17:03:19.793329: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Total chunks created: 5\n",
            "Total chunks created: 5\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RcSksmoHwz4H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}